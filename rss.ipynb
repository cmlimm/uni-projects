{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from gensim.summarization import keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-82c15c327564>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcleanr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "test = feedparser.parse('https://shikimori.one/forum/news.rss')\n",
    "test2 = test.entries\n",
    "cleanr = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "test2[0].published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in test2[:10]:\n",
    "    bs = BeautifulSoup(x.summary).get_text()\n",
    "    print(re.sub('\\.(?=\\w)', '.\\1', bs))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-10-12T20:50:23Z'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "github = feedparser.parse('https://github.com/cmlimm.private.atom?token=AD6MEE2WRZKT3K3424KCDXV3YWQEW')\n",
    "gitent = github['entries']\n",
    "gitent[10].published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g0stly starred eternnoir/pyTelegramBotAPI\n",
      "https://github.com/eternnoir/pyTelegramBotAPI\n",
      "\n",
      "anafisa starred matveyplevako/pyaterochka-bot\n",
      "https://github.com/matveyplevako/pyaterochka-bot\n",
      "\n",
      "anafisa starred matveyplevako/Operating-System-Course\n",
      "https://github.com/matveyplevako/Operating-System-Course\n",
      "\n",
      "g0stly made g0stly/unecon-lab-assignments public\n",
      "https://github.com/g0stly/unecon-lab-assignments\n",
      "\n",
      "kirill-toldov created a repository kirill-toldov/Clock\n",
      "https://github.com/kirill-toldov/Clock//\n",
      "\n",
      "anafisa created a repository anafisa/News-Bot\n",
      "https://github.com/anafisa/News-Bot//\n",
      "\n",
      "dm-fedorov created a repository dm-fedorov/data-analysis\n",
      "https://github.com/dm-fedorov/data-analysis//\n",
      "\n",
      "anafisa started following arsb29\n",
      "https://github.com/arsb29\n",
      "\n",
      "Nikita-Osipov created a repository Nikita-Osipov/Rss_project\n",
      "https://github.com/Nikita-Osipov/Rss_project//\n",
      "\n",
      "anafisa created a repository anafisa/Coursework1\n",
      "https://github.com/anafisa/Coursework1//\n",
      "\n",
      "whatislove-spirin created a repository whatislove-spirin/perfect_clock_lab\n",
      "https://github.com/whatislove-spirin/perfect_clock_lab//\n",
      "\n",
      "Nikita-Osipov started following AlexandrErofeevsky\n",
      "https://github.com/AlexandrErofeevsky\n",
      "\n",
      "Nikita-Osipov started following cmlimm\n",
      "https://github.com/cmlimm\n",
      "\n",
      "Nikita-Osipov started following dansobolev\n",
      "https://github.com/dansobolev\n",
      "\n",
      "AlexandrErofeevsky started following Nikita-Osipov\n",
      "https://github.com/Nikita-Osipov\n",
      "\n",
      "kirillzx created a repository kirillzx/Agent-based-modeling\n",
      "https://github.com/kirillzx/Agent-based-modeling//\n",
      "\n",
      "anafisa created a repository anafisa/Coursework2\n",
      "https://github.com/anafisa/python_coursework//\n",
      "\n",
      "kirillzx created a repository kirillzx/Math-projects\n",
      "https://github.com/kirillzx/Math-projects//\n",
      "\n",
      "g0stly started following anafisa\n",
      "https://github.com/anafisa\n",
      "\n",
      "kirillzx created a repository kirillzx/Projects\n",
      "https://github.com/kirillzx/Projects//\n",
      "\n",
      "g0stly started following MariaKrepko\n",
      "https://github.com/MariaKrepko\n",
      "\n",
      "AlexandrErofeevsky started following MariaKrepko\n",
      "https://github.com/MariaKrepko\n",
      "\n",
      "AlexandrErofeevsky started following DashaSorokina\n",
      "https://github.com/DashaSorokina\n",
      "\n",
      "anafisa created a repository anafisa/Alarm-clock\n",
      "https://github.com/anafisa/alarm_clock_project//\n",
      "\n",
      "anafisa started following whatislove-spirin\n",
      "https://github.com/whatislove-spirin\n",
      "\n",
      "whatislove-spirin started following anafisa\n",
      "https://github.com/anafisa\n",
      "\n",
      "anafisa started following g0stly\n",
      "https://github.com/g0stly\n",
      "\n",
      "g0stly started following anafisa\n",
      "https://github.com/anafisa\n",
      "\n",
      "kirill-toldov started following AlexandrErofeevsky\n",
      "https://github.com/AlexandrErofeevsky\n",
      "\n",
      "kirillzx started following dm-fedorov\n",
      "https://github.com/dm-fedorov\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in gitent:\n",
    "    cleantext = re.sub(cleanr, '', x.title)\n",
    "    #tt1 = re.sub(' +', ' ', re.sub('[\\n\\t\\r]+', '', cleantext))\n",
    "    print(re.sub('^ ', '', cleantext))\n",
    "    print(x['link'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-10-20T12:15:00+00:00'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt = feedparser.parse('https://www.youtube.com/feeds/videos.xml?channel_id=UCU9pX8hKcrx06XfOB-VQLdw')\n",
    "ytent = yt['entries']\n",
    "ytent[5].published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minecraft Combat Test Snapshot 3 : Chopping Enchantment & Invulnerability Cool Down Removed\n",
      "https://www.youtube.com/watch?v=nkNue6uCC3Y\n",
      "\n",
      "Hermitcraft VI 864 Demise Dare's & Pacified Pillagers!\n",
      "https://www.youtube.com/watch?v=9Vbr_5uZzHU\n",
      "\n",
      "Minecraft 1.15 Snapshot 19w44a The Hoglin, Stackable Honey Bottles! & Crazy Evoker Fangs\n",
      "https://www.youtube.com/watch?v=vcF1MVYSloM\n",
      "\n",
      "Hermitcraft VI 863 Scamming Tango & IDEA's First Diamonds!\n",
      "https://www.youtube.com/watch?v=Z5BjpJRmuEk\n",
      "\n",
      "Minecraft : The Evolution Of My Minecraft Bases\n",
      "https://www.youtube.com/watch?v=bpm-YTucLrA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in ytent[:5]:\n",
    "    cleantext = re.sub(cleanr, '', x.title)\n",
    "    tt1 = re.sub(' +', ' ', re.sub('[\\n\\t\\r]+', '', cleantext))\n",
    "    print(re.sub('^ ', '', tt1))\n",
    "    print(x['link'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testre = re.compile('.+\\..+')\n",
    "print(re.match(testre, 'https://shikimori.one/forum/news.rss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testre1 = re.compile('(У|у)далить ленты \\w+( \\w+)*$')\n",
    "print(re.match(testre1, 'Удалить ленты mom mom mom'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mon, 04 Nov 2019 10:00:00 +0000'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arch = feedparser.parse('http://feeds.feedburner.com/Archdaily?ad_name=footer-links')\n",
    "archent = arch['entries']\n",
    "archent[1].published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in archent:\n",
    "    #bs = BeautifulSoup(x.summary).get_text()\n",
    "    #cont = BeautifulSoup(x.content[0]['value']).find(\"img\")['src']\n",
    "    #print(cont)\n",
    "    #print(re.sub('\\.(?=\\w)', '.\\1', bs))\n",
    "    #print()\n",
    "    cleantext = re.sub(cleanr, '', x.title)\n",
    "    tt1 = re.sub(' +', ' ', re.sub('[\\n\\t\\r]+', '', cleantext))\n",
    "    print(re.sub('^ ', '', tt1))\n",
    "    print(x['link'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = {'1':['a', 'b', 'c'], '2':['q', 'w', 'e']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for feed in keywords:\n",
    "    print(feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'a' in keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from langdetect import detect\n",
    "from langcodes import Language\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk import word_tokenize\n",
    "import re\n",
    "\n",
    "def get_description(article, feed, keywords):\n",
    "    text = re.sub('\\.(?=\\w)', '.\\1', BeautifulSoup(article.summary, 'html.parser').get_text())\n",
    "    if find_keywords(article.title + text, keywords):\n",
    "        if feed['summary']:\n",
    "            if len(text) > 3000:\n",
    "                text = text[:3000]+'...\\nПродолжение по ссылке'\n",
    "            return '<b>' + article.title + '</b>\\n' + text + '\\n' + article.link\n",
    "        else:\n",
    "            return article.title + '\\n' + article.link\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def find_keywords(text, keywords):\n",
    "    lang = Language.make(language=detect(text)).language_name().lower()\n",
    "    stemmer = SnowballStemmer(lang)\n",
    "    keywords = [(word.lower(), stemmer.stem(word)) for word in keywords]\n",
    "    text = word_tokenize(text)\n",
    "    for key in keywords:\n",
    "        for word in text:\n",
    "                if word == key[0] or word == key[1] or stemmer.stem(word) == key[0] or stemmer.stem(word) == key[1]:\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "sample = 'С 3 по 4 ноября в Киото проходит открытая церемония памяти погибших при пожаре.\u0001Добрые слова и поддержка со всех концов света, которые вы отправляли с того дня, достигли наших сотрудников и очень сильно помогли нам вновь пойти вперёд.  Мы потеряли много друзей и коллег, которых ждало яркое будущее, и среди нас осталось много тяжелораненых. Мы будем нести с собой печаль всегда, но любовь и страсть, которые мы испытываем к своим работам, а также уверенное дыхание, наполнявшее то место, глубоко выбиты на наших телах и позволяют нам жить дальше.  Чувства, что мы получили от вас, чувства, что доверили нам наши друзья и коллеги, чувства, что мы шлём в будущее...  Мы соединим эти чувства и составим эти эмоции вместе, и пойдём дальше.  Мы продолжим создавать анимацию для всего мира, в помощь тем, у кого есть мечты и надежды, и впечатлять их.  Пожалуйста, присмотрите за тем, как мы будем продвигаться.  Kyoto Animation Co., Ltd.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_keywords(sample, ['Kyoto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
