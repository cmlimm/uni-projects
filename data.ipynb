{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['1SorcerersStone.txt', \n",
    "             '2ChamberofSecrets.txt',\n",
    "             '3ThePrisonerOfAzkaban.txt',\n",
    "             '4TheGobletOfFire.txt',\n",
    "             '5OrderofthePhoenix.txt',\n",
    "             '6TheHalfBloodPrince.txt',\n",
    "             '7DeathlyHollows.txt']\n",
    "with open('harrypotter.txt', 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_text_filename = 'harrypotter.txt'\n",
    "text_filename = 'harrypotter_cleaned.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(text_filename, 'w') as file_write:\n",
    "    with open(initial_text_filename, \"r\") as file_read:\n",
    "        for line in file_read:\n",
    "            # удаляем окаймляющие кавычки из строк\n",
    "            line = line.strip('\"\"')\n",
    "            \n",
    "            # удаляем имена собственные\n",
    "            names = re.compile(r'[A-Z][a-z]+')\n",
    "            line = re.sub(names, '', line)\n",
    "            \n",
    "            # удаляем артикли\n",
    "            names = re.compile(r\"'|’\")\n",
    "            line = re.sub(names, '', line)\n",
    "            \n",
    "            # разделяем строки на логические составляющие по знакам препинания\n",
    "            marks = re.compile(r'\\.|\\:|;|\\?|!|--|\"')\n",
    "            line = re.sub(marks, ':SPLIT:', line)\n",
    "            \n",
    "            # удаляем запятые\n",
    "            comma = re.compile(r\",\")\n",
    "            line = re.sub(comma, '', line)\n",
    "            \n",
    "            # удаляем тире\n",
    "            comma = re.compile(r\"-\")\n",
    "            line = re.sub(comma, ' ', line)\n",
    "            \n",
    "            line = line.strip('\\n')\n",
    "            lines = line.split(':SPLIT:')\n",
    "            for line in lines:\n",
    "                # убираем возможные окаймляющие пробелы\n",
    "                line = line.strip(' ')\n",
    "                # разделяем строку на слова\n",
    "                line = line.split(' ')\n",
    "                # каждое слово переводим в нижний регистр\n",
    "                line = list(map(lambda word: word.lower(), line))\n",
    "                # если строка не состоит из одного слова то записываем её в файл\n",
    "                if len(line) != 1:\n",
    "                    line = ' '.join(line)+'\\n'\n",
    "                    file_write.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество слов с повторениями:  925975\n",
      "Количество уникальных слов: 21071\n",
      "Пример из списка всех слов: rry\n",
      "Пример из списка всех предложений: ['rry', 'and', 'the', 's']\n"
     ]
    }
   ],
   "source": [
    "all_words = []\n",
    "all_sent = []\n",
    "with open(text_filename, 'r') as file:\n",
    "    for line in file:\n",
    "        words = line.split()\n",
    "        all_words += words\n",
    "        all_sent += [words]\n",
    "\n",
    "print(\"Количество слов с повторениями: \", len(all_words))\n",
    "all_words_norep = list(set(all_words))\n",
    "print(\"Количество уникальных слов:\", len(all_words_norep))\n",
    "print(\"Пример из списка всех слов:\", all_words[0])\n",
    "print(\"Пример из списка всех предложений:\", all_sent[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_words = {}\n",
    "for word in all_words_norep:\n",
    "    next_words[word] = {}\n",
    "    \n",
    "next_words['acting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'as': 1,\n",
       " 'him': 3,\n",
       " 'it': 3,\n",
       " 'to': 15,\n",
       " 'potion': 9,\n",
       " 'those': 1,\n",
       " 'at': 1,\n",
       " 'not': 1,\n",
       " 'yeh': 1,\n",
       " 'since': 1,\n",
       " 'lives': 1,\n",
       " 'with': 8,\n",
       " 'of': 3,\n",
       " 'hearing': 1,\n",
       " 'this': 1,\n",
       " 'life': 1,\n",
       " 'them': 1,\n",
       " 'a': 1,\n",
       " 'for': 2,\n",
       " 'me': 2,\n",
       " 'knitting': 1,\n",
       " 'stuff': 1,\n",
       " 'potions': 4,\n",
       " 'being': 1,\n",
       " 'porion': 1,\n",
       " 'and': 4,\n",
       " 'her': 4,\n",
       " 'my': 1,\n",
       " 'is': 1,\n",
       " 'you': 3,\n",
       " 'in': 1,\n",
       " 'if': 1,\n",
       " 'the': 1,\n",
       " 'loyalty': 1,\n",
       " 'again': 1,\n",
       " 'which': 1,\n",
       " 'did': 1,\n",
       " 'that': 1,\n",
       " 'some': 1}"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for sentence in all_sent:\n",
    "    n_words = len(sentence)\n",
    "    for word_ind in range(n_words):\n",
    "        current_word = sentence[word_ind]\n",
    "        # если слово не последнее в строке, то увеличиваем количество раз, \n",
    "        # которое следующее слово встретилось после текущего\n",
    "        if word_ind != n_words - 1:\n",
    "            next_word = sentence[word_ind + 1]\n",
    "            if next_word in next_words[current_word]:\n",
    "                next_words[current_word][next_word] += 1\n",
    "            else:\n",
    "                next_words[current_word][next_word] = 1\n",
    "\n",
    "next_words['love']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_words = {}\n",
    "for word in all_words_norep:\n",
    "    prev_words[word] = {}\n",
    "    \n",
    "prev_words['acting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is': 1,\n",
       " 'that': 2,\n",
       " 'll': 1,\n",
       " 'id': 10,\n",
       " 'a': 6,\n",
       " 'their': 1,\n",
       " 'really': 1,\n",
       " 'd': 3,\n",
       " 'found': 1,\n",
       " 'i': 9,\n",
       " 'to': 3,\n",
       " 'of': 4,\n",
       " 'tangled': 1,\n",
       " 'in': 10,\n",
       " 'the': 2,\n",
       " 'hed': 3,\n",
       " 'surely': 1,\n",
       " 's': 3,\n",
       " 'you': 2,\n",
       " 'no': 1,\n",
       " 'doesnt': 1,\n",
       " 'who': 2,\n",
       " 'do': 1,\n",
       " 'powerful': 1,\n",
       " 'create': 1,\n",
       " 'imitate': 1,\n",
       " 'obsessive': 1,\n",
       " 'theyd': 1,\n",
       " 'would': 1,\n",
       " 'unrequited': 1,\n",
       " 'different': 1,\n",
       " 'bring': 1,\n",
       " 'strong': 1,\n",
       " 'with': 1,\n",
       " 'undying': 1,\n",
       " 'disappointed': 1,\n",
       " 'swallowed': 1,\n",
       " 'can': 2,\n",
       " 'just': 1,\n",
       " 'not': 3,\n",
       " 'more': 1,\n",
       " 'my': 1,\n",
       " 'youd': 1,\n",
       " 'isnt': 1,\n",
       " 'was': 1,\n",
       " 'her': 2,\n",
       " 'and': 1,\n",
       " 'without': 1,\n",
       " 'it': 1,\n",
       " 'though': 1,\n",
       " 'solution': 1,\n",
       " 'great': 1,\n",
       " 'our': 1,\n",
       " 'professor': 1,\n",
       " 'him': 1}"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for sentence in all_sent:\n",
    "    n_words = len(sentence)\n",
    "    for word_ind in range(n_words - 1, 0, -1):\n",
    "        current_word = sentence[word_ind]\n",
    "        # если слово не последнее в строке, то увеличиваем количество раз, \n",
    "        # которое следующее слово встретилось после текущего\n",
    "        prev_word = sentence[word_ind - 1]\n",
    "        if prev_word in prev_words[current_word]:\n",
    "            prev_words[current_word][prev_word] += 1\n",
    "        else:\n",
    "            prev_words[current_word][prev_word] = 1\n",
    "\n",
    "prev_words['love']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'as': 0.011494252873563218,\n",
       " 'him': 0.034482758620689655,\n",
       " 'it': 0.034482758620689655,\n",
       " 'to': 0.1724137931034483,\n",
       " 'potion': 0.10344827586206896,\n",
       " 'those': 0.011494252873563218,\n",
       " 'at': 0.011494252873563218,\n",
       " 'not': 0.011494252873563218,\n",
       " 'yeh': 0.011494252873563218,\n",
       " 'since': 0.011494252873563218,\n",
       " 'lives': 0.011494252873563218,\n",
       " 'with': 0.09195402298850575,\n",
       " 'of': 0.034482758620689655,\n",
       " 'hearing': 0.011494252873563218,\n",
       " 'this': 0.011494252873563218,\n",
       " 'life': 0.011494252873563218,\n",
       " 'them': 0.011494252873563218,\n",
       " 'a': 0.011494252873563218,\n",
       " 'for': 0.022988505747126436,\n",
       " 'me': 0.022988505747126436,\n",
       " 'knitting': 0.011494252873563218,\n",
       " 'stuff': 0.011494252873563218,\n",
       " 'potions': 0.04597701149425287,\n",
       " 'being': 0.011494252873563218,\n",
       " 'porion': 0.011494252873563218,\n",
       " 'and': 0.04597701149425287,\n",
       " 'her': 0.04597701149425287,\n",
       " 'my': 0.011494252873563218,\n",
       " 'is': 0.011494252873563218,\n",
       " 'you': 0.034482758620689655,\n",
       " 'in': 0.011494252873563218,\n",
       " 'if': 0.011494252873563218,\n",
       " 'the': 0.011494252873563218,\n",
       " 'loyalty': 0.011494252873563218,\n",
       " 'again': 0.011494252873563218,\n",
       " 'which': 0.011494252873563218,\n",
       " 'did': 0.011494252873563218,\n",
       " 'that': 0.011494252873563218,\n",
       " 'some': 0.011494252873563218}"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in next_words:\n",
    "    total = sum(next_words[word].values())\n",
    "    for next_word in next_words[word]:\n",
    "        next_words[word][next_word] = next_words[word][next_word]/total\n",
    "        \n",
    "next_words['love']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is': 0.009523809523809525,\n",
       " 'that': 0.01904761904761905,\n",
       " 'll': 0.009523809523809525,\n",
       " 'id': 0.09523809523809523,\n",
       " 'a': 0.05714285714285714,\n",
       " 'their': 0.009523809523809525,\n",
       " 'really': 0.009523809523809525,\n",
       " 'd': 0.02857142857142857,\n",
       " 'found': 0.009523809523809525,\n",
       " 'i': 0.08571428571428572,\n",
       " 'to': 0.02857142857142857,\n",
       " 'of': 0.0380952380952381,\n",
       " 'tangled': 0.009523809523809525,\n",
       " 'in': 0.09523809523809523,\n",
       " 'the': 0.01904761904761905,\n",
       " 'hed': 0.02857142857142857,\n",
       " 'surely': 0.009523809523809525,\n",
       " 's': 0.02857142857142857,\n",
       " 'you': 0.01904761904761905,\n",
       " 'no': 0.009523809523809525,\n",
       " 'doesnt': 0.009523809523809525,\n",
       " 'who': 0.01904761904761905,\n",
       " 'do': 0.009523809523809525,\n",
       " 'powerful': 0.009523809523809525,\n",
       " 'create': 0.009523809523809525,\n",
       " 'imitate': 0.009523809523809525,\n",
       " 'obsessive': 0.009523809523809525,\n",
       " 'theyd': 0.009523809523809525,\n",
       " 'would': 0.009523809523809525,\n",
       " 'unrequited': 0.009523809523809525,\n",
       " 'different': 0.009523809523809525,\n",
       " 'bring': 0.009523809523809525,\n",
       " 'strong': 0.009523809523809525,\n",
       " 'with': 0.009523809523809525,\n",
       " 'undying': 0.009523809523809525,\n",
       " 'disappointed': 0.009523809523809525,\n",
       " 'swallowed': 0.009523809523809525,\n",
       " 'can': 0.01904761904761905,\n",
       " 'just': 0.009523809523809525,\n",
       " 'not': 0.02857142857142857,\n",
       " 'more': 0.009523809523809525,\n",
       " 'my': 0.009523809523809525,\n",
       " 'youd': 0.009523809523809525,\n",
       " 'isnt': 0.009523809523809525,\n",
       " 'was': 0.009523809523809525,\n",
       " 'her': 0.01904761904761905,\n",
       " 'and': 0.009523809523809525,\n",
       " 'without': 0.009523809523809525,\n",
       " 'it': 0.009523809523809525,\n",
       " 'though': 0.009523809523809525,\n",
       " 'solution': 0.009523809523809525,\n",
       " 'great': 0.009523809523809525,\n",
       " 'our': 0.009523809523809525,\n",
       " 'professor': 0.009523809523809525,\n",
       " 'him': 0.009523809523809525}"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in prev_words:\n",
    "    total = sum(prev_words[word].values())\n",
    "    for prev_word in prev_words[word]:\n",
    "        prev_words[word][prev_word] = prev_words[word][prev_word]/total\n",
    "        \n",
    "prev_words['love']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохранение словарей в файл\n",
    "with open('next_words.json', 'w') as file:\n",
    "    json.dump(next_words, file)\n",
    "    \n",
    "with open('prev_words.json', 'w') as file:\n",
    "    json.dump(prev_words, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('next_words.json', 'r') as file:\n",
    "    next_words = json.load(file)\n",
    "    \n",
    "with open('prev_words.json', 'r') as file:\n",
    "    prev_words = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# подсчитываем частоту встречаемости каждого слова\n",
    "words_count = {}\n",
    "for word in all_words_norep:\n",
    "    words_count[word] = all_words.count(word)\n",
    "    \n",
    "words_count['love']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00011555387564459084"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_prob = words_count.copy()\n",
    "all_words_n = len(all_words)\n",
    "for word in words_prob:\n",
    "    words_prob[word] = words_prob[word]/all_words_n\n",
    "    \n",
    "words_prob['love']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохранение словарей в файл\n",
    "with open('words_count.json', 'w') as file:\n",
    "    json.dump(words_count, file)\n",
    "\n",
    "with open('words_prob.json', 'w') as file:\n",
    "    json.dump(words_prob, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('words_count.json', 'r') as file:\n",
    "    words_count = json.load(file)\n",
    "\n",
    "with open('words_prob.json', 'r') as file:\n",
    "    words_prob = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-17.97621408419379"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import log, inf\n",
    "\n",
    "def bayes(previous, word, neighbours, words_dict):\n",
    "    prob_word = log(words_dict[word])\n",
    "    prob = 0\n",
    "    for prev in previous:\n",
    "        try:\n",
    "            prob += log(neighbours[word][prev])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    \n",
    "    if prob == 0:\n",
    "        return -inf\n",
    "    else:\n",
    "        return prob+prob_word\n",
    "\n",
    "bayes(['i', 'love'], 'you', next_words, words_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n(previous, n, all_dict, prev_dict, words_dict):\n",
    "    word_probs = {}\n",
    "    for word in all_dict:\n",
    "        word_probs[word] = bayes(previous, word, prev_dict, words_dict)\n",
    "    \n",
    "    return sorted(word_probs, key=word_probs.get, reverse=True)[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['but', 'if', 'when', 'what', 'as']\n",
      "['dont', 'was', 'think', 'have', 'am']\n"
     ]
    }
   ],
   "source": [
    "print(top_n(['i', 'love'], 5, all_words, next_words, words_prob))\n",
    "print(top_n(['i', 'love'], 5, all_words, prev_words, words_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['told', 'tell', 'with', 'for', 'help']\n",
      "['i', 'me', 'in', 'what', 'im']\n"
     ]
    }
   ],
   "source": [
    "print(top_n(['kill', 'me'], 5, all_words, next_words, words_prob))\n",
    "print(top_n(['kill', 'me'], 5, all_words, prev_words, words_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'she', 'face', 'hair', 'am']\n",
      "['dont', 'think', 'have', 'am', 'know']\n"
     ]
    }
   ],
   "source": [
    "print(top_n('i was wondering'.split(), 5, all_words, next_words, words_prob)) \n",
    "print(top_n('i was wondering'.split(), 5, all_words, prev_words, words_prob)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['into', 'gave', 'took', 'such', 'made']\n",
      "['dont', 'few', 'am', 'moment', 'very']\n"
     ]
    }
   ],
   "source": [
    "print(top_n('i brew a potion'.split(), 5, all_words, next_words, words_prob)) \n",
    "print(top_n('i brew a potion'.split(), 5, all_words, prev_words, words_prob)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
